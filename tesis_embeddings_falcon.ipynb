{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lordjuacs/tesis/blob/master/tesis_embeddings_falcon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLibqkUaJ2p7"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes sentence_transformers faiss-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDWlM5OwUIGv",
        "outputId": "f51f9144-fff3-49c3-c71c-8869517f4173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  1 23:05:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
        "import torch\n",
        "import faiss\n"
      ],
      "metadata": {
        "id": "sLhKUKsXlnum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "dataset_path = \"tesis_dataset.csv\"\n",
        "df = pd.read_csv(dataset_path)\n"
      ],
      "metadata": {
        "id": "dAxoXyC0mslN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sentence embedding model (example: 'paraphrase-MiniLM-L6-v2')\n",
        "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "# Create embeddings for the dataset\n",
        "dataset_embeddings = embedding_model.encode(df['pregunta'].tolist())\n"
      ],
      "metadata": {
        "id": "oaP9aL-cmudW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the embeddings in a vector database (use your preferred database library)\n",
        "\n",
        "# For example, using faiss\n",
        "index = faiss.IndexFlatL2(dataset_embeddings.shape[1])\n",
        "index.add(dataset_embeddings)\n"
      ],
      "metadata": {
        "id": "Jv29Vx0Vm1DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User inserts custom question\n",
        "user_question = \"Explícame qué es el intercambio estudiantil\"\n",
        "\n",
        "# Convert user question to embedding\n",
        "user_question_embedding = embedding_model.encode(user_question)\n"
      ],
      "metadata": {
        "id": "lj5YnY-gm6bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send to LLM Chain for answer generation\n",
        "model = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",  # task\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "b_9uquWHnHF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature': 0.7, 'top_p': 0.7, \"generation_config.max_new_tokens\": 200, \"num_return_sequence\": 1})\n"
      ],
      "metadata": {
        "id": "3kPcRXysovK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLM Chain\n",
        "template = \"\"\"\n",
        "Eres un chatabot inteligente que sirve como trabajador en la Universidad de Ingeniería y Tecnología (UTEC). Ayúdame a responder la siguiente pregunta de manera directa y concisa.\n",
        "Pregunta: {pregunta}\n",
        "Respuesta:\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"pregunta\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
      ],
      "metadata": {
        "id": "T4bLhfn8nFWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RzvE5Azxx7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit this cell to test different questions and run to get model answers\n",
        "\n",
        "# Example question\n",
        "user_question = \"¿Qué becas hay?\"\n",
        "\n",
        "# Convert user question to embedding\n",
        "user_question_embedding = embedding_model.encode(user_question)\n",
        "\n",
        "# Apply similarity search\n",
        "k = 5  # Number of neighbors to retrieve\n",
        "_, most_similar_indices = index.search(user_question_embedding.reshape(1, -1), k)\n",
        "\n",
        "# Retrieve the most similar question-answer pair\n",
        "most_similar_index = most_similar_indices[0][0]\n",
        "most_similar_question = df['pregunta'][most_similar_index]\n",
        "most_similar_answer = df['respuesta'][most_similar_index]\n",
        "\n",
        "# Use the retrieved question as input to LLM Chain\n",
        "generated_answer = llm_chain.run(most_similar_question)\n",
        "\n",
        "# Display results\n",
        "print(f\"User Question: {user_question}\")\n",
        "print(f\"Most Similar Question: {most_similar_question}\")\n",
        "print(f\"Retrieved Answer: {most_similar_answer}\")\n",
        "print(f\"Generated Answer: {generated_answer}\")\n"
      ],
      "metadata": {
        "id": "8DRgqbPJnCIJ",
        "outputId": "516ce7ff-2e96-4e8a-8575-b96565b59daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Question: ¿Qué becas hay?\n",
            "Most Similar Question: ¿Qué son las becas financiadas por terceros y cómo se gestionan?\n",
            "Retrieved Answer: Las becas financiadas por terceros provienen de convenios o auspicios con empresas o entidades y se gestionan estableciendo criterios específicos de selección y otorgamiento.\n",
            "Generated Answer:  Las becas son programas de apoyo financiero ofrecidos por terceros a estudiantes de tercer ciclo, en particular para que aborden temas específicos a los que están interesados. Se administra en función de la legislación de la administración federal del estado. A su administración se remite un presupuesto y un plan de estudios a cumplir.\n",
            "A continuación, se presentan algunos puntos clave para administrar las becas financiadas por terceros.\n",
            "- Aplicar en la Universidad. Una vez aprobada la\n"
          ]
        }
      ]
    }
  ]
}